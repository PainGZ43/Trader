# Phase 4: AI ëª¨ë¸ ê°œë°œ ìƒì„¸ ê³„íš

**ëª©í‘œ**: ë”¥ëŸ¬ë‹ ê¸°ë°˜ ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶•

**ì˜ˆìƒ ê¸°ê°„**: 5-7ì¼

---

## 1. AI ëª¨ë¸ ì•„í‚¤í…ì²˜ ì„¤ê³„

### 1.1 ëª¨ë¸ ì •ì˜

#### [NEW] [ai/model.py](file:///e:/GitHub/UpbitTrader/ai/model.py)

**ì£¼ìš” ê¸°ëŠ¥**:

#### 1.1.1 LSTM ëª¨ë¸

```python
import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential
from keras.layers import LSTM, GRU, Dense, Dropout, BatchNormalization
from keras.optimizers import Adam
from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

class PricePredictor Model:
    """ê°€ê²© ì˜ˆì¸¡ LSTM ëª¨ë¸"""
    
    def __init__(self, input_shape, model_type='lstm'):
        """
        Args:
            input_shape: (time_steps, features)
            model_type: 'lstm' or 'gru'
        """
        self.input_shape = input_shape
        self.model_type = model_type
        self.model = None
        
    def build_model(self, lstm_units=[128, 64, 32], dropout_rate=0.2):
        """ëª¨ë¸ êµ¬ì¶•"""
        model = Sequential()
        
        # ì²« ë²ˆì§¸ LSTM/GRU ë ˆì´ì–´
        if self.model_type == 'lstm':
            model.add(LSTM(
                units=lstm_units[0],
                return_sequences=True,
                input_shape=self.input_shape
            ))
        else:
            model.add(GRU(
                units=lstm_units[0],
                return_sequences=True,
                input_shape=self.input_shape
            ))
        
        model.add(Dropout(dropout_rate))
        model.add(BatchNormalization())
        
        # ì¤‘ê°„ ë ˆì´ì–´ë“¤
        for units in lstm_units[1:-1]:
            if self.model_type == 'lstm':
                model.add(LSTM(units=units, return_sequences=True))
            else:
                model.add(GRU(units=units, return_sequences=True))
            
            model.add(Dropout(dropout_rate))
            model.add(BatchNormalization())
        
        # ë§ˆì§€ë§‰ LSTM/GRU ë ˆì´ì–´
        if self.model_type == 'lstm':
            model.add(LSTM(units=lstm_units[-1]))
        else:
            model.add(GRU(units=lstm_units[-1]))
        
        model.add(Dropout(dropout_rate))
        model.add(BatchNormalization())
        
        # ì¶œë ¥ ë ˆì´ì–´
        model.add(Dense(units=32, activation='relu'))
        model.add(Dense(units=16, activation='relu'))
        model.add(Dense(units=1))  # ê°€ê²© ì˜ˆì¸¡
        
        # ì»´íŒŒì¼
        model.compile(
            optimizer=Adam(learning_rate=0.001),
            loss='mse',
            metrics=['mae', 'mape']
        )
        
        self.model = model
        return model
    
    def summary(self):
        """ëª¨ë¸ ìš”ì•½"""
        if self.model:
            return self.model.summary()
```

#### 1.1.2 ë©€í‹°íƒœìŠ¤í¬ ëª¨ë¸ (ê°€ê²© + ë°©í–¥)

```python
class MultiTaskModel:
    """ê°€ê²© ì˜ˆì¸¡ + ë°©í–¥ ì˜ˆì¸¡ ëª¨ë¸"""
    
    def __init__(self, input_shape):
        self.input_shape = input_shape
        self.model = None
    
    def build_model(self):
        """ë©€í‹°íƒœìŠ¤í¬ ëª¨ë¸ êµ¬ì¶•"""
        from keras.layers import Input
        from keras.models import Model
        
        # ì…ë ¥
        inputs = Input(shape=self.input_shape)
        
        # ê³µìœ  ë ˆì´ì–´
        x = LSTM(128, return_sequences=True)(inputs)
        x = Dropout(0.2)(x)
        x = LSTM(64)(x)
        x = Dropout(0.2)(x)
        
        # ê°€ê²© ì˜ˆì¸¡ ë¸Œëœì¹˜
        price_branch = Dense(32, activation='relu')(x)
        price_output = Dense(1, name='price')(price_branch)
        
        # ë°©í–¥ ì˜ˆì¸¡ ë¸Œëœì¹˜ (ìƒìŠ¹/í•˜ë½/ë³´í•©)
        direction_branch = Dense(32, activation='relu')(x)
        direction_output = Dense(3, activation='softmax', name='direction')(direction_branch)
        
        # ëª¨ë¸ ìƒì„±
        model = Model(inputs=inputs, outputs=[price_output, direction_output])
        
        # ì»´íŒŒì¼
        model.compile(
            optimizer=Adam(learning_rate=0.001),
            loss={
                'price': 'mse',
                'direction': 'categorical_crossentropy'
            },
            loss_weights={
                'price': 0.7,
                'direction': 0.3
            },
            metrics={
                'price': ['mae'],
                'direction': ['accuracy']
            }
        )
        
        self.model = model
        return model
```

---

## 2. ë°ì´í„° ì¤€ë¹„

### 2.1 í•™ìŠµ ë°ì´í„° ìƒì„±

#### [NEW] [ai/data_generator.py](file:///e:/GitHub/UpbitTrader/ai/data_generator.py)

```python
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split

class TrainingDataGenerator:
    """í•™ìŠµ ë°ì´í„° ìƒì„± í´ë˜ìŠ¤"""
    
    def __init__(self, lookback=60, forecast_horizon=1):
        """
        Args:
            lookback: ê³¼ê±° ëª‡ ê°œì˜ ë°ì´í„°ë¥¼ ë³¼ì§€ (time steps)
            forecast_horizon: ë¯¸ë˜ ëª‡ ìŠ¤í… ì˜ˆì¸¡í• ì§€
        """
        self.lookback = lookback
        self.forecast_horizon = forecast_horizon
    
    def create_sequences(self, data, target_column='close'):
        """ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ìƒì„±
        
        Returns:
            X: (samples, lookback, features)
            y: (samples,)
        """
        X, y = [], []
        
        for i in range(len(data) - self.lookback - self.forecast_horizon + 1):
            # ì…ë ¥: ê³¼ê±° lookbackê°œì˜ ë°ì´í„°
            X.append(data[i:i + self.lookback])
            
            # íƒ€ê²Ÿ: forecast_horizon í›„ì˜ ê°€ê²©
            y.append(data[i + self.lookback + self.forecast_horizon - 1][target_column])
        
        return np.array(X), np.array(y)
    
    def prepare_training_data(self, df, feature_columns, target_column='close', 
                            test_size=0.2, validation_size=0.1):
        """í•™ìŠµ ë°ì´í„° ì¤€ë¹„"""
        
        # í”¼ì²˜ ì„ íƒ
        data = df[feature_columns].values
        
        # ì‹œí€€ìŠ¤ ìƒì„±
        X, y = self.create_sequences(data, target_column)
        
        # Train/Val/Test ë¶„í• 
        X_temp, X_test, y_temp, y_test = train_test_split(
            X, y, test_size=test_size, shuffle=False
        )
        
        X_train, X_val, y_train, y_val = train_test_split(
            X_temp, y_temp, test_size=validation_size, shuffle=False
        )
        
        print(f"ğŸ“Š ë°ì´í„° í˜•íƒœ:")
        print(f"  Train: X={X_train.shape}, y={y_train.shape}")
        print(f"  Val:   X={X_val.shape}, y={y_val.shape}")
        print(f"  Test:  X={X_test.shape}, y={y_test.shape}")
        
        return {
            'X_train': X_train, 'y_train': y_train,
            'X_val': X_val, 'y_val': y_val,
            'X_test': X_test, 'y_test': y_test
        }
    
    def create_direction_labels(self, prices, threshold=0.001):
        """ë°©í–¥ ë ˆì´ë¸” ìƒì„± (0: í•˜ë½, 1: ë³´í•©, 2: ìƒìŠ¹)"""
        changes = (prices - np.roll(prices, 1)) / np.roll(prices, 1)
        
        labels = np.zeros(len(changes))
        labels[changes > threshold] = 2  # ìƒìŠ¹
        labels[changes < -threshold] = 0  # í•˜ë½
        labels[(changes >= -threshold) & (changes <= threshold)] = 1  # ë³´í•©
        
        # One-hot encoding
        from keras.utils import to_categorical
        return to_categorical(labels, num_classes=3)
```

---

## 3. ëª¨ë¸ í•™ìŠµ

### 3.1 í•™ìŠµ íŒŒì´í”„ë¼ì¸

#### [NEW] [ai/trainer.py](file:///e:/GitHub/UpbitTrader/ai/trainer.py)

```python
import os
from datetime import datetime
import matplotlib.pyplot as plt
from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard

class ModelTrainer:
    """ëª¨ë¸ í•™ìŠµ í´ë˜ìŠ¤"""
    
    def __init__(self, model, model_name='price_predictor'):
        self.model = model
        self.model_name = model_name
        self.history = None
        
    def train(self, X_train, y_train, X_val, y_val, 
              epochs=100, batch_size=32, patience=10):
        """ëª¨ë¸ í•™ìŠµ"""
        
        # ì½œë°± ì„¤ì •
        callbacks = self._get_callbacks(patience)
        
        print(f"ğŸ¤– ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
        print(f"  Epochs: {epochs}")
        print(f"  Batch size: {batch_size}")
        
        # í•™ìŠµ
        self.history = self.model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            epochs=epochs,
            batch_size=batch_size,
            callbacks=callbacks,
            verbose=1
        )
        
        print("âœ… í•™ìŠµ ì™„ë£Œ")
        
        return self.history
    
    def _get_callbacks(self, patience):
        """ì½œë°± í•¨ìˆ˜ë“¤"""
        
        # ëª¨ë¸ ì €ì¥ ê²½ë¡œ
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        model_dir = f'./models/{self.model_name}'
        os.makedirs(model_dir, exist_ok=True)
        
        model_path = os.path.join(model_dir, f'best_model_{timestamp}.h5')
        
        callbacks = [
            # ì¡°ê¸° ì¢…ë£Œ
            EarlyStopping(
                monitor='val_loss',
                patience=patience,
                restore_best_weights=True,
                verbose=1
            ),
            
            # ìµœì  ëª¨ë¸ ì €ì¥
            ModelCheckpoint(
                filepath=model_path,
                monitor='val_loss',
                save_best_only=True,
                verbose=1
            ),
            
            # í•™ìŠµë¥  ê°ì†Œ
            ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=5,
                min_lr=1e-7,
                verbose=1
            ),
            
            # TensorBoard
            TensorBoard(
                log_dir=f'./logs/{self.model_name}/{timestamp}',
                histogram_freq=1
            )
        ]
        
        return callbacks
    
    def plot_training_history(self, save_path=None):
        """í•™ìŠµ ì´ë ¥ ì‹œê°í™”"""
        if self.history is None:
            print("í•™ìŠµ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        fig, axes = plt.subplots(1, 2, figsize=(15, 5))
        
        # Loss
        axes[0].plot(self.history.history['loss'], label='Train Loss')
        axes[0].plot(self.history.history['val_loss'], label='Val Loss')
        axes[0].set_title('Model Loss')
        axes[0].set_xlabel('Epoch')
        axes[0].set_ylabel('Loss')
        axes[0].legend()
        axes[0].grid(True)
        
        # MAE
        axes[1].plot(self.history.history['mae'], label='Train MAE')
        axes[1].plot(self.history.history['val_mae'], label='Val MAE')
        axes[1].set_title('Model MAE')
        axes[1].set_xlabel('Epoch')
        axes[1].set_ylabel('MAE')
        axes[1].legend()
        axes[1].grid(True)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path)
        else:
            plt.show()
    
    def evaluate(self, X_test, y_test):
        """ëª¨ë¸ í‰ê°€"""
        print("\nğŸ“Š ëª¨ë¸ í‰ê°€:")
        results = self.model.evaluate(X_test, y_test, verbose=0)
        
        print(f"  Test Loss: {results[0]:.6f}")
        print(f"  Test MAE: {results[1]:.6f}")
        print(f"  Test MAPE: {results[2]:.2f}%")
        
        return results
```

---

## 4. ì˜ˆì¸¡ ì„œë¹„ìŠ¤

### 4.1 ì‹¤ì‹œê°„ ì˜ˆì¸¡

#### [NEW] [ai/predictor.py](file:///e:/GitHub/UpbitTrader/ai/predictor.py)

```python
import numpy as np
from keras.models import load_model

class PricePredictor:
    """ê°€ê²© ì˜ˆì¸¡ ì„œë¹„ìŠ¤"""
    
    def __init__(self, model_path=None):
        self.model = None
        self.scaler = None
        
        if model_path:
            self.load_model(model_path)
    
    def load_model(self, model_path):
        """ëª¨ë¸ ë¡œë“œ"""
        try:
            self.model = load_model(model_path)
            print(f"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {model_path}")
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def predict(self, data):
        """ì˜ˆì¸¡ ìˆ˜í–‰
        
        Args:
            data: (lookback, features) í˜•íƒœì˜ ì…ë ¥ ë°ì´í„°
        
        Returns:
            predicted_price: ì˜ˆì¸¡ ê°€ê²©
        """
        if self.model is None:
            raise ValueError("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ì…ë ¥ í˜•íƒœ ì¡°ì • (batch ì°¨ì› ì¶”ê°€)
        if len(data.shape) == 2:
            data = np.expand_dims(data, axis=0)
        
        # ì˜ˆì¸¡
        prediction = self.model.predict(data, verbose=0)
        
        return prediction[0][0]
    
    def predict_with_confidence(self, data, n_predictions=10):
        """ì‹ ë¢°ë„ì™€ í•¨ê»˜ ì˜ˆì¸¡
        
        ì—¬ëŸ¬ ë²ˆ ì˜ˆì¸¡í•˜ì—¬ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚°
        """
        predictions = []
        
        for _ in range(n_predictions):
            pred = self.predict(data)
            predictions.append(pred)
        
        mean_pred = np.mean(predictions)
        std_pred = np.std(predictions)
        confidence = 1 - (std_pred / mean_pred)  # ê°„ë‹¨í•œ ì‹ ë¢°ë„ ê³„ì‚°
        
        return {
            'predicted_price': mean_pred,
            'std': std_pred,
            'confidence': max(0, min(1, confidence))  # 0-1 ë²”ìœ„ë¡œ ì œí•œ
        }
    
    def generate_signal(self, current_price, predicted_price, threshold=0.02):
        """ë§¤ë§¤ ì‹œê·¸ë„ ìƒì„±
        
        Args:
            current_price: í˜„ì¬ ê°€ê²©
            predicted_price: ì˜ˆì¸¡ ê°€ê²©
            threshold: ì‹œê·¸ë„ ë°œìƒ ì„ê³„ê°’ (2%)
        
        Returns:
            signal: 'buy', 'sell', 'hold'
            change_percent: ì˜ˆìƒ ë³€í™”ìœ¨
        """
        change_percent = (predicted_price - current_price) / current_price
        
        if change_percent > threshold:
            signal = 'buy'
        elif change_percent < -threshold:
            signal = 'sell'
        else:
            signal = 'hold'
        
        return {
            'signal': signal,
            'change_percent': change_percent * 100,
            'current_price': current_price,
            'predicted_price': predicted_price
        }
```

---

## 5. ëª¨ë¸ í‰ê°€ ë° ê²€ì¦

### 5.1 ì„±ëŠ¥ í‰ê°€

#### [NEW] [ai/evaluator.py](file:///e:/GitHub/UpbitTrader/ai/evaluator.py)

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

class ModelEvaluator:
    """ëª¨ë¸ í‰ê°€ í´ë˜ìŠ¤"""
    
    @staticmethod
    def calculate_metrics(y_true, y_pred):
        """í‰ê°€ ì§€í‘œ ê³„ì‚°"""
        mse = mean_squared_error(y_true, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_true, y_pred)
        mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
        r2 = r2_score(y_true, y_pred)
        
        return {
            'MSE': mse,
            'RMSE': rmse,
            'MAE': mae,
            'MAPE': mape,
            'R2': r2
        }
    
    @staticmethod
    def plot_predictions(y_true, y_pred, title='Predictions vs Actual'):
        """ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”"""
        fig, axes = plt.subplots(2, 1, figsize=(15, 10))
        
        # ì‹œê³„ì—´ ë¹„êµ
        axes[0].plot(y_true, label='Actual', alpha=0.7)
        axes[0].plot(y_pred, label='Predicted', alpha=0.7)
        axes[0].set_title(title)
        axes[0].set_xlabel('Time')
        axes[0].set_ylabel('Price')
        axes[0].legend()
        axes[0].grid(True)
        
        # ì‚°ì ë„
        axes[1].scatter(y_true, y_pred, alpha=0.5)
        axes[1].plot([y_true.min(), y_true.max()], 
                     [y_true.min(), y_true.max()], 
                     'r--', lw=2)
        axes[1].set_title('Scatter Plot')
        axes[1].set_xlabel('Actual Price')
        axes[1].set_ylabel('Predicted Price')
        axes[1].grid(True)
        
        plt.tight_layout()
        plt.show()
    
    @staticmethod
    def calculate_directional_accuracy(y_true, y_pred):
        """ë°©í–¥ ì •í™•ë„ ê³„ì‚°"""
        true_direction = np.sign(np.diff(y_true))
        pred_direction = np.sign(np.diff(y_pred))
        
        accuracy = np.mean(true_direction == pred_direction) * 100
        
        return accuracy
```

---

## 6. ìë™ ì¬í•™ìŠµ

### 6.1 ì¬í•™ìŠµ ìŠ¤ì¼€ì¤„ëŸ¬

#### [NEW] [ai/retraining_scheduler.py](file:///e:/GitHub/UpbitTrader/ai/retraining_scheduler.py)

```python
import schedule
import time
from datetime import datetime

class RetrainingScheduler:
    """ëª¨ë¸ ìë™ ì¬í•™ìŠµ ìŠ¤ì¼€ì¤„ëŸ¬"""
    
    def __init__(self, trainer, data_pipeline, market='KRW-BTC'):
        self.trainer = trainer
        self.data_pipeline = data_pipeline
        self.market = market
    
    def retrain_model(self):
        """ëª¨ë¸ ì¬í•™ìŠµ ì‹¤í–‰"""
        print(f"\n{'='*50}")
        print(f"ğŸ”„ ëª¨ë¸ ì¬í•™ìŠµ ì‹œì‘: {datetime.now()}")
        print(f"{'='*50}\n")
        
        # 1. ìµœì‹  ë°ì´í„° ìˆ˜ì§‘
        df = self.data_pipeline.get_processed_data(self.market, days=90, use_cache=False)
        
        # 2. í•™ìŠµ ë°ì´í„° ì¤€ë¹„
        # ... (ë°ì´í„° ì¤€ë¹„ ë¡œì§)
        
        # 3. ëª¨ë¸ í•™ìŠµ
        # ... (í•™ìŠµ ë¡œì§)
        
        # 4. í‰ê°€
        # ... (í‰ê°€ ë¡œì§)
        
        print(f"\nâœ… ì¬í•™ìŠµ ì™„ë£Œ: {datetime.now()}\n")
    
    def schedule_weekly_retraining(self, day='sunday', time='02:00'):
        """ì£¼ê°„ ì¬í•™ìŠµ ìŠ¤ì¼€ì¤„"""
        schedule.every().sunday.at(time).do(self.retrain_model)
        
        print(f"ğŸ“… ì£¼ê°„ ì¬í•™ìŠµ ìŠ¤ì¼€ì¤„ ì„¤ì •: ë§¤ì£¼ {day} {time}")
        
        while True:
            schedule.run_pending()
            time.sleep(3600)  # 1ì‹œê°„ë§ˆë‹¤ ì²´í¬
    
    def schedule_daily_retraining(self, time='02:00'):
        """ì¼ì¼ ì¬í•™ìŠµ ìŠ¤ì¼€ì¤„"""
        schedule.every().day.at(time).do(self.retrain_model)
        
        print(f"ğŸ“… ì¼ì¼ ì¬í•™ìŠµ ìŠ¤ì¼€ì¤„ ì„¤ì •: ë§¤ì¼ {time}")
        
        while True:
            schedule.run_pending()
            time.sleep(3600)
```

---

## ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

### âœ… ëª¨ë¸ êµ¬ì¶•
- [ ] LSTM ëª¨ë¸ ì •ì˜
- [ ] GRU ëª¨ë¸ ì •ì˜
- [ ] ë©€í‹°íƒœìŠ¤í¬ ëª¨ë¸ ì •ì˜
- [ ] í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •

### âœ… ë°ì´í„° ì¤€ë¹„
- [ ] ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ìƒì„±
- [ ] Train/Val/Test ë¶„í• 
- [ ] ì •ê·œí™”/í‘œì¤€í™”
- [ ] í”¼ì²˜ ì„ íƒ

### âœ… í•™ìŠµ
- [ ] ëª¨ë¸ í•™ìŠµ ì‹¤í–‰
- [ ] ì¡°ê¸° ì¢…ë£Œ ë™ì‘ í™•ì¸
- [ ] ìµœì  ëª¨ë¸ ì €ì¥
- [ ] í•™ìŠµ ì´ë ¥ ì‹œê°í™”

### âœ… í‰ê°€
- [ ] MSE, MAE, MAPE ê³„ì‚°
- [ ] ë°©í–¥ ì •í™•ë„ ê³„ì‚°
- [ ] ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”
- [ ] R2 ìŠ¤ì½”ì–´ í™•ì¸

### âœ… ì˜ˆì¸¡
- [ ] ì‹¤ì‹œê°„ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
- [ ] ì‹ ë¢°ë„ ê³„ì‚°
- [ ] ì‹œê·¸ë„ ìƒì„±
- [ ] ëª¨ë¸ ë¡œë“œ/ì €ì¥

---

## ë‹¤ìŒ ë‹¨ê³„

Phase 4 ì™„ë£Œ í›„:
- âœ… Phase 5: íŠ¸ë ˆì´ë”© ë¡œì§ êµ¬í˜„
- ğŸ’¼ AI ì‹ í˜¸ ê¸°ë°˜ ì£¼ë¬¸ ì‹¤í–‰
- ğŸ¯ ë¦¬ìŠ¤í¬ ê´€ë¦¬ í†µí•©

> [!IMPORTANT]
> AI ëª¨ë¸ì˜ ì˜ˆì¸¡ì€ ì°¸ê³ ìš©ì…ë‹ˆë‹¤. ì‹¤ì œ ìˆ˜ìµì„ ë³´ì¥í•˜ì§€ ì•Šìœ¼ë©°, ì¶©ë¶„í•œ ë°±í…ŒìŠ¤íŒ…ê³¼ ê²€ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤.

> [!TIP]
> ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë†’ì´ë ¤ë©´ ë‹¤ì–‘í•œ í”¼ì²˜ë¥¼ ì¶”ê°€í•˜ê³ , í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ ì§„í–‰í•˜ì„¸ìš”. AutoML ë„êµ¬ í™œìš©ë„ ê³ ë ¤í•´ë³´ì„¸ìš”.
